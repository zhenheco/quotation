/**
 * å°‡å°å‡ºçš„è³‡æ–™å°å…¥åˆ° Cloudflare D1
 *
 * åŸ·è¡Œæ–¹å¼ï¼š
 * ```bash
 * # æœ¬åœ°æ¸¬è©¦
 * npx tsx scripts/migration/import-to-d1.ts --local
 *
 * # é ç«¯éƒ¨ç½²
 * npx tsx scripts/migration/import-to-d1.ts --remote
 * ```
 */

import fs from 'fs/promises'
import path from 'path'
import { execSync } from 'child_process'

const DATABASE_NAME = 'quotation-system-db'
const EXPORT_DIR = path.join(process.cwd(), 'data-export')

const TABLES = [
  // è·³é roles å’Œ permissionsï¼ˆD1 schema å·²åŒ…å«é è¨­å€¼ï¼‰
  // 'roles',
  // 'permissions',
  'role_permissions',
  'user_roles',
  'companies',
  'company_members',

  // å†å°å…¥æœ‰ä¾è³´é—œä¿‚çš„è¡¨
  'customers',
  'products',
  'quotations',
  'quotation_items',
  'quotation_shares',
  'quotation_versions',
  'customer_contracts',
  'payments',
  'exchange_rates'
]

interface ImportOptions {
  isLocal: boolean
}

/**
 * D1 schema æ¬„ä½æ˜ å°„ï¼ˆåªä¿ç•™ D1 ä¸­å­˜åœ¨çš„æ¬„ä½ï¼‰
 */
const D1_SCHEMA_FIELDS: Record<string, string[]> = {
  role_permissions: ['id', 'role_id', 'permission_id', 'created_at'],
  user_roles: ['id', 'user_id', 'role_id', 'assigned_by', 'created_at', 'updated_at'],
  companies: ['id', 'name', 'logo_url', 'signature_url', 'passbook_url', 'tax_id', 'bank_name', 'bank_account', 'bank_code', 'address', 'phone', 'email', 'website', 'created_at', 'updated_at'],
  company_members: ['id', 'company_id', 'user_id', 'role_id', 'is_owner', 'is_active', 'joined_at', 'updated_at'],
  customers: ['id', 'user_id', 'company_id', 'name', 'email', 'phone', 'address', 'tax_id', 'contact_person', 'created_at', 'updated_at'],
  products: ['id', 'user_id', 'company_id', 'sku', 'name', 'description', 'unit_price', 'currency', 'category', 'cost_price', 'cost_currency', 'profit_margin', 'supplier', 'base_price', 'created_at', 'updated_at'],
  quotations: ['id', 'user_id', 'company_id', 'customer_id', 'quotation_number', 'status', 'issue_date', 'valid_until', 'currency', 'subtotal', 'tax_rate', 'tax_amount', 'discount', 'total_amount', 'notes', 'created_at', 'updated_at'],
  quotation_items: ['id', 'quotation_id', 'product_id', 'description', 'quantity', 'unit_price', 'currency', 'discount', 'tax_rate', 'subtotal', 'total', 'sort_order', 'created_at'],
  quotation_shares: ['id', 'quotation_id', 'share_token', 'expires_at', 'created_at'],
  quotation_versions: ['id', 'quotation_id', 'version_number', 'data', 'created_by', 'created_at'],
  customer_contracts: ['id', 'customer_id', 'company_id', 'quotation_id', 'contract_number', 'contract_file_url', 'contract_file_name', 'status', 'signed_date', 'start_date', 'end_date', 'total_amount', 'currency', 'payment_terms', 'notes', 'created_at', 'updated_at'],
  payments: ['id', 'contract_id', 'company_id', 'amount', 'currency', 'payment_date', 'payment_method', 'status', 'notes', 'created_at', 'updated_at'],
  exchange_rates: ['id', 'from_currency', 'to_currency', 'rate', 'rate_date', 'source', 'created_at', 'updated_at']
}

/**
 * è½‰æ› PostgreSQL è³‡æ–™åˆ° SQLite æ ¼å¼
 */
function transformRow(row: any, tableName: string): any {
  // åªä¿ç•™ D1 schema ä¸­å®šç¾©çš„æ¬„ä½
  const allowedFields = D1_SCHEMA_FIELDS[tableName] || Object.keys(row)
  const transformed: any = {}

  for (const field of allowedFields) {
    if (row[field] !== undefined) {
      transformed[field] = row[field]
    }
  }

  // è½‰æ› JSON æ¬„ä½
  const jsonFields: Record<string, string[]> = {
    customers: ['name', 'address', 'contact_person'],
    products: ['name', 'description'],
    companies: ['name', 'address'],
    quotation_versions: ['data']
  }

  if (jsonFields[tableName]) {
    for (const field of jsonFields[tableName]) {
      if (transformed[field] && typeof transformed[field] === 'object') {
        transformed[field] = JSON.stringify(transformed[field])
      }
    }
  }

  // è½‰æ›å¸ƒæ—å€¼ (PostgreSQL true/false â†’ SQLite 1/0)
  for (const key in transformed) {
    if (typeof transformed[key] === 'boolean') {
      transformed[key] = transformed[key] ? 1 : 0
    }
  }

  return transformed
}

/**
 * ç”Ÿæˆ INSERT SQL èªå¥
 */
function generateInsertSQL(tableName: string, rows: any[]): string {
  if (rows.length === 0) {
    return ''
  }

  const keys = Object.keys(rows[0])
  const values = rows.map(row => {
    const transformedRow = transformRow(row, tableName)
    const vals = keys.map(key => {
      const value = transformedRow[key]
      if (value === null || value === undefined) {
        return 'NULL'
      }
      if (typeof value === 'string') {
        return `'${value.replace(/'/g, "''")}'`
      }
      return value
    })
    return `(${vals.join(', ')})`
  })

  const sql = `INSERT INTO ${tableName} (${keys.join(', ')}) VALUES\n${values.join(',\n')};`
  return sql
}

/**
 * å°å…¥å–®å€‹è¡¨
 */
async function importTable(tableName: string, options: ImportOptions): Promise<void> {
  console.log(`ğŸ“¥ å°å…¥ ${tableName}...`)

  try {
    // è®€å– JSON æª”æ¡ˆ
    const filePath = path.join(EXPORT_DIR, `${tableName}.json`)
    const fileContent = await fs.readFile(filePath, 'utf-8')
    const rows = JSON.parse(fileContent)

    if (rows.length === 0) {
      console.log(`âš ï¸  ${tableName}: ç„¡è³‡æ–™ï¼Œè·³é`)
      return
    }

    // ç”Ÿæˆ SQL
    const sql = generateInsertSQL(tableName, rows)

    // å„²å­˜ SQL åˆ°æš«å­˜æª”æ¡ˆ
    const tempSQLFile = path.join(EXPORT_DIR, `temp_${tableName}.sql`)
    await fs.writeFile(tempSQLFile, sql)

    // åŸ·è¡Œ wrangler d1 execute
    const flag = options.isLocal ? '--local' : '--remote'
    const command = `npx wrangler d1 execute ${DATABASE_NAME} ${flag} --file=${tempSQLFile}`

    execSync(command, { stdio: 'inherit' })

    // åˆªé™¤æš«å­˜æª”æ¡ˆ
    await fs.unlink(tempSQLFile)

    console.log(`âœ… ${tableName}: ${rows.length} ç­†è³‡æ–™å·²å°å…¥`)
  } catch (err) {
    console.error(`âŒ ${tableName} å°å…¥éŒ¯èª¤:`, err)
  }
}

async function main() {
  const args = process.argv.slice(2)
  const isLocal = args.includes('--local')
  const isRemote = args.includes('--remote')

  if (!isLocal && !isRemote) {
    console.error('âŒ è«‹æŒ‡å®š --local æˆ– --remote')
    console.error('ä½¿ç”¨æ–¹å¼ï¼š')
    console.error('  npx tsx scripts/migration/import-to-d1.ts --local')
    console.error('  npx tsx scripts/migration/import-to-d1.ts --remote')
    process.exit(1)
  }

  const mode = isLocal ? 'æœ¬åœ°' : 'é ç«¯'
  console.log(`ğŸš€ é–‹å§‹å°å…¥è³‡æ–™åˆ° D1 (${mode} æ¨¡å¼)...\n`)

  // æª¢æŸ¥å°å‡ºç›®éŒ„æ˜¯å¦å­˜åœ¨
  try {
    await fs.access(EXPORT_DIR)
  } catch {
    console.error(`âŒ æ‰¾ä¸åˆ° data-export/ ç›®éŒ„`)
    console.error('è«‹å…ˆåŸ·è¡Œ export-from-supabase.ts å°å‡ºè³‡æ–™')
    process.exit(1)
  }

  // ä¾åºå°å…¥æ¯å€‹è¡¨
  for (const table of TABLES) {
    await importTable(table, { isLocal })
  }

  console.log(`\nâœ… æ‰€æœ‰è³‡æ–™å·²å°å…¥åˆ° D1 (${mode} æ¨¡å¼)`)

  // é©—è­‰
  console.log('\nğŸ“Š é©—è­‰è³‡æ–™ç­†æ•¸...')
  for (const table of TABLES) {
    try {
      const flag = isLocal ? '--local' : '--remote'
      const command = `npx wrangler d1 execute ${DATABASE_NAME} ${flag} --command="SELECT COUNT(*) as count FROM ${table}"`

      console.log(`${table}:`)
      execSync(command, { stdio: 'inherit' })
    } catch (err) {
      console.error(`âŒ ${table} é©—è­‰å¤±æ•—`)
    }
  }
}

main().catch(console.error)
